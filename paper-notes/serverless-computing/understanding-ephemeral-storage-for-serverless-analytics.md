# Understanding Ephemeral Storage for Serverless Analytics

* [Understanding Ephemeral Storage for Serverless Analytics](https://www.usenix.org/system/files/conference/atc18/atc18-klimovic-serverless.pdf)

这篇文章说是understanding就真的是understanding，写得相当友好易懂~

Serverless computing是云中越来越流行的执行模型。 借助AWS Lambda，Google Cloud Functions和Azure Functions等服务，用户可以将应用程序编写为无状态函数的集合，直接部署到Serverless框架，而不是在具有预分配资源的传统虚拟机上运行任务。 云提供商将用户任务调度到物理资源上，承诺根据应用程序需求自动扩展，并仅为其任务消耗的细粒度资源向用户收费。Serverless computing的弹性和细粒度计费优势吸引了更广泛的应用，包括比如交互式数据分析。

在Serverless computing平台上运行分析工作负载的关键挑战是在任务之间有效地共享数据。

以刚刚提到的交互式数据分析为例，它的特点就是一个不断循环的过程，我先扔一些离散的目标进去，然后得到一些问题，根据得到的问题分析自己的数据问答这些问题，然后生成新的问题……与由响应事件触发器而执行的单个任务组成的简单事件驱动应用程序相比，分析通常由多个阶段组成，并且需要在任务阶段之间共享中间结果。

在一些传统的分析框架（例如，Spark，Hadoop）中，缓冲本地存储中的中间数据，并直接通过网络在task之间交换数据。相比之下，Serverless computing框架通过要求task无状态来实现高弹性和可扩展性。换句话说，task的本地文件系统和子进程仅限于task本身的生命周期。此外，由于Serverless平台不公开对task的调度和放置控制，因此难以直接在task之间进行通信。于是，解决task间通信的自然方法是将中间数据存储在**公共的远程存储服务**中，这种存储称为Ephemeral Storage，即**短暂存储**。将task之间交换的数据称为**短暂数据**。

在Serverless分析作业中有多种存储选择可用于这种数据共享，当然不同选项都提供不同的成本，性能和可扩展性权衡。 像Amazon的S3（Simple Storage Service）这样的托管对象存储服务为提供商管理的存储资源提供了按需使用的容量和带宽，虽然它主要用于长期数据存储，但也可用于短暂数据。 而像Redis和Memcached这样的 in-memory key-value 存储以DRAM的高成本来提供高性能，它们还要求用户管理自己的存储VM。 

这篇文章主要就描述了三种不同serverless应用程序中数据共享的I/O要求，分别是MapReduce排序，分布式软件编译和视频处理。 使用AWS Lambda作为serverless平台，使用三种不同类型的存储系统来分析应用程序性能：

* 基于磁盘的托管对象存储服务（Amazon S3）

* 基于DRAM的内存中的键值存储（ElastiCache Redis）

* 基于Flash的分布式存储系统（带有ReFlex Flash后端的Apache Crail ）

论文使用了了三种不同的serverless分析应用程序，对它们分别做了一些描述，从后文的内容中也可以看出论文团队为什么要选择这三种。

* 并行软件构建：
  * 使用了一个名为`gg`的框架来自动合成软件构建系统的依赖树，并协调lambda调用以进行分布式编译。 
  * 每个lambda从短暂存储中获取其依赖关系，计算（即根据阶段编译，存档或链接），并写入输出文件。 
  * 编译阶段lambdas读取源文件，通常最多10个KB。 虽然55％的文件只读取一次（由一个lambda读取），但其他文件读取数百次（并行读取多个lambda），例如`glibc`库文件。 
  * Lambdas存档或链接读取对象的大小最多10个MB。 使用`gg`来编译具有850 MB短暂数据的`cmake`

* MapReduce排序：
  * 在AWS Lambda上实现了MapReduce样式排序应用程序。 
  * 映射lambdas从长期存储（S3）获取输入文件并将中间文件写入短暂存储。 减少lambdas合并并对从短暂存储读取的中间数据进行排序，并将输出文件写入S3。 
  * 排序是I / O密集型的。 例如，当使用500 lambda排序100 GB时，测量到最多7.5GB / s。 每个中间文件只写入和读取一次，其大小与数据集大小成正比，与worker数量成反比。

* 视频分析：
  * 使用Thousand Island Scanner（THIS）在lambdas上运行分布式视频处理。 
  * 输入是编码视频，分为批次并上传到短暂存储。 第一阶段lambdas从短暂存储中读取一批编码视频帧并写回解码视频帧。 然后，每个lambda启动第二阶段lambda，其从短暂存储中读取一组解码帧，计算MXNET深度学习分类算法并输出分类结果。 总的短暂存储容量为6 GB。

在具体的实验中，论文比较了这三种不同的存储系统，用于serverless分析中的短暂数据共享，从以下几个角度讨论应用程序如何影响短暂的存储需求。

* 对延迟敏感的作业：
  * 三种应用程序中，只有`gg`显示对存储延迟的一些敏感性，因为访问的大多数文件都低于100 KB。 
  * 实验结果表明， 与S3相比，Redis存储的延迟更低，最多可达100个并发lambda。但是随着增加并发性，S3和Redis的运行时会收敛，因为作业最终会在AWS Lambda上受到计算限制。

* 并行性有限的作业：
  * 虽然serverless 平台允许用户通过启动许多并发lambda来利用高应用程序并行性，但是具有固有受限并行性的作业（例如，由于lambda之间的依赖性）可能经历lambda资源瓶颈（例如，memory，计算和/或网络带宽限制）而不是存储瓶颈。
  * 再次`gg`的案例。软件构建过程的第一阶段具有高并行性，因为每个文件都可以独立地进行预处理，编译和组装。但是，后续存档和链接文件的lambdas取决于早期阶段的输出。
  * 论文的图5描绘了使用gg编译具有多达650个并发lambdas的`cmake`时的每个lambda读取，计算和写入时间。使用Redis比使用S3相比，能将lambda在I / O上花费的平均时间从51％减少到11％。但是，无论存储系统如何，作业大约需要30秒才能完成。这是因为优化I / O不会影响具有特别高的计算延迟的lambda，而这会成为瓶颈

* 吞吐量密集型作业：
  * MapReduce排序是一种具有丰富并行性的I / O密集型应用程序。
    * 论文中的图6显示了每个lambda在I / O上花费的平均时间，并计算出对100 GB数据集进行排序。
    * 使用S3作为输入/输出文件，并将性能与S3，Redis，CrailReFlex作为短暂存储进行比较。将短暂数据存储在远程DRAM（Redis）或远程Flash（Crail-ReFlex）中可以提供类似的端到端性能，因为在存储集群中提供了足够的带宽，并且瓶颈变成了lambda CPU的使用率。随着我们增加lambda的数量，性能会线性扩展。 
  * 视频分析是另一种具有丰富并行性的应用程序。 
    * 论文中图7显示了每个阶段中lambdas读取，计算和写入数据的平均时间。 
    * Redis和CrailReFlex相比，从S3读取和写入短暂数据会增加执行时间。 由于Flash上的读写干扰，Crail-ReFlex的第2阶段读取时间比Redis高。这是因为第一阶段的一些lambdas比其他人更早完成并发射第二阶段lambdas。 因此，对于某些第二阶段lambda的读取I / O会干扰仍在运行的第一阶段lambdas的写入请求。 

根据实验结果，论文给出了一些看法：

* 期望的短暂存储属性：
  * 一个应用程序可以在一个执行阶段包含数千个lambda，在另一个执行阶段只包含几个lambda，存储系统应该具有高弹性。
  * 该系统还应支持高IOPS（Input/Output Operations Per Second）和高吞吐量。
  * 因为数据访问的粒度变化很大，因此存储小型和大型对象应该考虑成本和性能效率。为了减轻用户管理存储群集的难度，存储服务应根据负载自动调整资源，并根据所使用的带宽和容量向用户收费。这有效地将serverless抽象扩展到存储。
  * 存储系统可以利用短暂数据的独特特征。也就是说，短暂的数据是短暂的，可以通过重新运行作业的任务轻松地重新生成。因此，与传统的长期存储不同，短暂的存储系统可以提供低数据持久性保证。此外，由于大多数短暂数据只被写入和读取一次（例如，mapper为特定的reducer写入中间结果），因此存储系统可以使用API优化容量使用，允许用户在读取数据后立即删除数据

* 存储介质的选择：存储系统可以通过向上和/或向外扩展资源来支持任意高吞吐量。更有趣的问题是哪种存储技术允许系统经济高效地满足应用程序吞吐量，延迟和容量要求。
  * 排序应用程序是最适合的用于基于Flash的短暂存储。 gg-cmake和视频分析工作属于DRAM制度。
  * 然而，观察到使用Flash以较低的每GB成本为这些应用程序提供类似的端到端性能，因为lambda CPU是瓶颈。具有并发短暂读写I/O的I/O密集型应用程序可能更喜欢DRAM存储，因为闪存尾部读取延迟随着并发写入而显着增加[18]。。

总的来说，为了支持serverless平台上的数据密集型分析，论文的分析推动了短暂存储服务的设计，该服务支持存储容量和吞吐量的自动和细粒度分配。 对于论文研究的三种不同应用，吞吐量比延迟更重要，闪存存储在性能和成本方面提供了良好的平衡。



[返回目录](../README.md)
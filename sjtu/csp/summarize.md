# 摘要

serverless 是这几年变得火热的一个概念，强调FaaS。这允许租户专注于开发他们的函数——专用于特定任务的小型应用程序。 一个函数通常在具有受限资源（如CPU时间和内存，AWS Lambda根据CPU内存分了好几个套餐）的专用函数实例（容器或其他类型的沙箱）中执行。 本文首先评估了目前几个主流无服务器平台的一些评估与测试。本文重点描述了无服务器的冷启动问题，描述关于冷启动进行的测试，并寻找可以优化相关缺陷的方案。本文之后给出了一些思考和解决方案。

# 1. 介绍

serverless 是这几年变得火热的一个概念，强调FaaS。这允许租户专注于开发他们的函数——专用于特定任务的小型应用程序。 一个函数通常在具有受限资源的专用函数实例（容器或其他类型的沙箱）中执行。 与传统的IaaS平台中的VM不同，只有在调用函数时才会启动函数实例，并在处理请求后立即进入休眠状态。 租户按每次调用收费，无需支付未使用和闲置的资源。

以AWS Lambda 作为 Serverless 服务平台为例子，租户需要考虑怎么用代码提供价值即可，甚至连可扩展、蓝绿部署等一系列的问题都不用考虑，Amazon 优秀的运营工程师已经帮助租户打造了这一系列的基础设施。并且与传统的 AWS 服务一样，如 EC2，它们都是按流量算钱的。如果要对一个运行的函数收费，考虑到的只有运行时间、CPU、内存占用、硬盘这几个条件。可针对于不同的需求，提供不同的 CPU 是一件很麻烦的事。对于代码来说，一个应用占用的硬盘空间几乎可以忽略不计。当然，这些应用会在你的 S3 上有一个备份。于是，诸如 AWS 采用的是运行时间 + 内存的计算方式，如表1所示：

| 内存 (MB) | 每个月的免费套餐秒数 | 每 100ms 的价格 (USD) |
| --------- | -------------------- | --------------------- |
| 128       | 3,200,000            | 0.000000208           |
| 192       | 2,133,333            | 0.000000313           |
| 256       | 1,600,000            | 0.000000417           |
| …         | …                    | …                     |
| 1024      | 400,000              | 0.000001667           |
| …         | …                    | …                     |

**表1：AWS Lambda的套餐规格**

在运行程序的时候，AWS 会统计出一个时间和内存，如下所示：

```
REPORT RequestId: 041138f9-bc81-11e7-aa63-0dbab83f773d  Duration: 2.49 ms   Billed Duration: 100 ms     Memory Size: 1024 MB    Max Memory Used: 20 MB
```

其中的 `Memory Size` 即是租户选用的套餐类型，`Duration` 即是运行的时间，`Max Memory Used` 是租户应用运行时占用的内存。根据租户的`Max Memory Used`数值及应用的计算量，可以很轻松地计算出我们所需要的套餐。

显然，Serverless平台具有这几个优点。1）运行方便，价格合理；2）减少运营成本，降低开发成本；3）实现快速上线，更快的部署流水线，更快的开发速度；4）自动扩展，适应微服务架构，系统安全性更高。但同样的，serverless带来了对应的几个问题：

1. **不适合长时间运行应用**：Serverless 在请求到来时才运行。这意味着，当应用不运行的时候就会进入 “休眠状态”，下次当请求来临时，应用将会需要一个启动时间，即冷启动。如果租户的应用需要一直长期不间断的运行、处理大量的请求，那么可能就不适合采用 Serverless 架构。在这种情况下，采用 EC2 这样的云服务器往往是一种更好的选择。因为 EC2 从价格上来说，更加便宜。
2. **冷启动时间**：如上所说，Serverless 应用存在一个冷启动时间的问题。本文将详细展示serverless平台下一些性能测试结果并揭示严峻的冷启动问题（§3）。

3. **完全依赖于第三方服务**：是的，当决定使用某个云服务的时候，也就意味着可能走了一条不归路。在这种情况下，只能将不重要的 API 放在 Serverless 上。当已经有大量的基础设施的时候，Serverless 对于租户来说，并不是一个好东西。当采用 Serverless 架构的时候，就意味着和特别的服务供应商绑定了。假设某个租户使用了 AWS 家的服务，那么该租户再将服务迁到 Google Cloud 上就没有那么容易了。首先他们需要修改一下系列的底层代码，能采取的应对方案，便是建立隔离层。这意味着，在设计应用的时候，就需要隔离 API 网关，隔离数据库层等等。这些也将带给租户一些额外的成本，可能*带来的问题会比解决的问题多*。
4. **不透明的API**：完全依赖于第三方服务的另一个问题是，对于提供API的背后，是不透明的。这就会导致租户有理由对供应商提供的服务表示担忧：比如平台说不同函数实例之前是隔离的，那么，隔离的质量如何呢？供应商的服务器在受到DDoS等攻击时展现的安全性怎么样？程序性能如何？

针对这些问题，本文首先描述了各个服务器平台的性能测试结果（§2），包括资源调度（§2.1），性能隔离（§2.2）和短暂存储的性能（§2.3），此外，本文针对serverless平台的关键瓶颈——冷启动进行了细致的描述评估（§3.1和§3.2）。本文根据冷启动问题进行了一些思考并罗列了目前的一些解决方案。最后，本文对冷启动的延迟进行了一些思考。

# 2. 性能测试

为了研究流行的serverless平台的资源管理机制和效率的快照，为开发人员提供了构建更可靠平台的性能基准和设计选项，并帮助租户改进无服务器平台的使用。Liang Wang等人对AWS Lambda，Azure Functions和Google Cloud Functions这三个大厂进行了大规模的测试！通过在这三个服务中启动了50,000多个函数实例，以表征其架构，性能和资源管理效率。为了研究无服务器任务之间进行通信和数据交换，Ana Klimovic等人在AWS Lambda平台上通过使用三种不同的serverless分析应用程序（并行软件构建，MapReduce排序和视频分析）进行了大量的测试。§2.1，§2.2和§2.3描述了他们的实验结果。

## 2.1 资源调度

Liang Wang等人研究了如何在实例冷启动延迟，生命周期，可伸缩性等方面在三个无服务平台中调度实例和VM。

首先是**可伸缩性**和**实例放置**，正如这些厂商声称的那样，响应于需求变化的弹性自动缩放是serverless模型的益处，因此需要衡量平台扩展的程度。

在支持并发执行方面，AWS是三项服务中最好的。N个并发调用总是产生N个并发运行的函数实例。 AWS可以轻松扩展到200个（最大测量并发级别）新鲜函数实例。在实例放置方面，AWS Lambda似乎将它为bin-packing问题，采取了一种贪心策略，尝试在现有活动VM上放置新的函数实例以最大化VM内存利用率，即实例内存大小之和除以3,328（这是测量到的最大VM聚合内存）。

Azure文档声明它将自动扩展到最多200个实例，用于基于Nodejs的单个函数，并且每10秒最多可以启动一个新的函数实例。 但是，在测试中，无论如何更改调用之间的间隔，最多只能看到10个函数实例同时为单个函数运行。 所有请求都由一小组函数实例处理。 并发运行的实例都不在同一个VM上。 因此，似乎Azure不会尝试在同一个VM上共同定位相同函数的函数实例。

Google未能提供所需的可扩展性，即使Google声称HTTP触发的函数会迅速扩展到所需的调用率。 通常，即使对于低并发级别（例如，10），也只有大约一半的预期实例数量可以同时启动，而其余的请求是排队的。

然后是**冷启动和VM配置**。使用冷启动来表示启动新函数实例的过程。 对于平台，冷启动可能涉及启动新容器，设置运行时环境以及部署函数，与重用现有函数实例（热启动）相比，这将花费更多时间来处理请求。 因此，冷启动可以显着影响应用程序响应性，进而影响用户体验。具体实验结果见§3.2

关于**实例生命周期和闲置实例回收**。将函数实例保持活动的最长时间定义为实例生命周期。 租户当然更喜欢长寿命，因为他们的应用程序将能够更长时间地保持内存状态（例如，数据库连接）并且从冷启动中受到更少的影响。为了有效地使用资源，serverless提供商关闭空闲实例以回收分配的资源。 我们定义实例在关闭之前可以保持空闲的最长时间，作为实例最大空闲时间。

*在更长的生命周期和更短的空闲时间之间存在权衡，因为维护更多空闲实例是浪费VM内存资源，而更少的准备服务实例导致更多冷启动。*

Azure函数实例的生命周期显着长于AWS和Google。在AWS中，所有设置的实例生命周期中值为6.2小时，最大值为8.3小时。 AWS中的主机VM通常寿命更长：观察到的最长VM内核正常运行时间为9.2小时。 当请求频率增加时，实例寿命反而趋于变短。 谷歌总体生命周期偏短，更大的内存往往具有更长的生命周期。 例如，当每五秒调用一次时，Google的128MB和2,048 MB内存的90％实例的生命周期分别为3-31分钟和19-580分钟。 因此，对于在繁重工作负载下具有小内存的函数，Google似乎积极地推出新实例而不是重用现有实例。 这可能会增加冷启动的性能损失。

在AWS中， 一个实例通常可以保持不活动状态最多27分钟。 如果VM上存在活动实例，则实例可以保持非活动状态较长时间。 通过每10秒发送一个请求，在给定的VM上保持一个实例处于活动状态，并发现：AWS仍然采用相同的策略来回收相同函数的空闲实例，但是观察到一些空闲实例在这种情况下可能会闲置1-3个小时。Azure和Google。 在Azure中，我们找不到一致的最大实例空闲时间。 我们在不同的日子重复了几次实验，发现最大空闲时间分别为22,40和120分钟。 在Google中，实例的空闲时间可能超过120分钟。 120分钟后，实例在18％的实验中保持活跃状态。

## 2.2 性能隔离

Liang Wang等人研究三个无服务平台中的性能隔离。性能隔离主要分为两方面，一方面是CPU利用率，一方面是I/O和网络。

为了测量**CPU利用率**，测试方法是测量函数使用`time.time()`（Python）或`Date.now()`（Nodejs）连续记录时间戳1,000 ms。度量实例CPU利用率定义为记录时间戳的1,000毫秒的分数，即在1,000毫秒的时间里使用了多少时间的CPU。

根据AWS，函数实例的CPU功率与其预先配置的内存成比例。 但是，AWS没有详细说明如何为实例分配CPU时间。论文进一步研究了如何在共存实例之间分配CPU时间，检查结果发现运行的实例公平地共享CPU，因为它们具有几乎相同的CPU利用率。 因此，AWS尝试仅基于函数内存为实例分配固定数量的CPU周期。

Azure和Google。 Google采用与AWS相同的机制来根据函数内存分配CPU周期。 在Google中，随着函数内存的增加，实例CPU利用率的中位数从11.1％到100％不等。 对于给定的memory大小，不同实例的速率的标准偏差非常低。Azure的CPU利用率差异较大，即使为实例分配了相同数量的内存，也是如此。 4-vCPU虚拟机上的实例往往获得更高的CPU份额。 1-vCPU VM和2-vCPU VM上实例的利用率分布实际上是相似的; 但是，当共存函数实例增加时，1-vCPU VM上的实例的CPU利用率下降得更厉害。

关于**I/O吞吐量和网络吞吐量**，在AWS中， 虽然聚合I / O和网络吞吐量保持相对稳定，但随着共存实例的增加，每个实例在I / O和网络资源中的份额都会减少。 在Azure中，实例的I / O和网络吞吐量也随着`colevel`的增加而下降，并且由于来自其他coreident实例的争用而波动。 更有趣的是，资源分配是根据函数实例恰好安排在哪种类型的VM来区分的。 在Google中，随着函数内存的增加，测量的I / O和网络吞吐量都会增加。但是Google在具有相同内存大小的不同实例测量的网络吞吐量会发生显着变化。 例如，在2,048 MB函数实例中测量的网络吞吐量在0.2 Mbps和321.4 Mbps之间波动。 论文发现了两种情况：（1）所有实例吞吐量在给定时间段内波动，与内存大小无关，或者（2）单个实例暂时遭受吞吐量下降的影响。 情况（1）可能是由于网络状况的变化，而情况（2）导致怀疑GCF租户实际上共享主机并遭受资源争用。更具体的测量方法和测试结果可以看论文详细内容。

以上的测试结果说明，AWS和Azure无法在共存实例之间提供适当的性能隔离，因此争用可能会导致性能显着下降。 在AWS中，他们将来自同一帐户的函数实例打包到VM上的事实意味着扩展函数会将相同的函数放在同一个VM上，从而导致资源争用和延长执行时间（更不用说更长的冷启动延迟）。 Azure具有类似的问题，另外一个问题是VM之间的争用在帐户之间产生。 后者还为服务攻击的交叉租户降级提供了可能性。

## 2.3 短暂存储

Ana Klimovic等人在AWS Lambda平台上通过使用三种不同的serverless分析应用程序（并行软件构建，MapReduce排序和视频分析）进行了大量的测试。 使用AWS Lambda作为serverless平台，使用三种不同类型的存储系统来分析应用程序性能（基于磁盘的托管对象存储服务（Amazon S3，基于DRAM的内存中的键值存储（ElastiCache Redis）和基于Flash的分布式存储系统（带有ReFlex Flash后端的Apache Crail ））以下是他们的测试结果：

- **对延迟敏感的作业**：三种应用程序中，只有并行软件构建显示对存储延迟的一些敏感性，因为访问的大多数文件都低于100 KB。实验结果表明， 与S3相比，Redis存储的延迟更低，最多可达100个并发lambda。但是随着增加并发性，S3和Redis的运行时会收敛，因为作业最终会在AWS Lambda上受到计算限制。
- **并行性有限的作业**：虽然serverless 平台允许用户通过启动许多并发lambda来利用高应用程序并行性，但是具有固有受限并行性的作业（例如，由于lambda之间的依赖性）可能经历lambda资源瓶颈（例如，memory，计算和/或网络带宽限制）而不是存储瓶颈。再次并行软件构建的案例，软件构建过程的第一阶段具有高并行性，因为每个文件都可以独立地进行预处理，编译和组装。但是，后续存档和链接文件的lambdas取决于早期阶段的输出。无论存储系统如何，作业大约需要30秒才能完成。这是因为优化I / O不会影响具有特别高的计算延迟的lambda，而这会成为瓶颈
- **吞吐量密集型作业**：MapReduce排序是一种具有丰富并行性的I / O密集型应用程序。使用S3作为输入/输出文件，并将性能与S3，Redis，CrailReFlex作为短暂存储进行比较。将短暂数据存储在远程DRAM（Redis）或远程Flash（Crail-ReFlex）中可以提供类似的端到端性能，因为在存储集群中提供了足够的带宽，并且瓶颈变成了lambda CPU的使用率。随着我们增加lambda的数量，性能会线性扩展。视频分析是另一种具有丰富并行性的应用程序。Redis和CrailReFlex相比，从S3读取和写入短暂数据会增加执行时间。 由于Flash上的读写干扰，Crail-ReFlex的第2阶段读取时间比Redis高。这是因为第一阶段的一些lambdas比其他人更早完成并发射第二阶段lambdas。 因此，对于某些第二阶段lambda的读取I / O会干扰仍在运行的第一阶段lambdas的写入请求。

## 2.4 讨论

Ana Klimovic等人的测试为期望的短暂存储属性提出了见解。为了支持serverless平台上的数据密集型分析，他们的分析推动了短暂存储服务的设计，该服务支持存储容量和吞吐量的自动和细粒度分配。 对于他们研究的三种不同应用，吞吐量比延迟更重要，闪存存储在性能和成本方面提供了良好的平衡。

尽管如此，在其他方面的测试中，延迟问题就成了性能测试中的一项关键因素。根据Liang Wang等人的测试结果，在资源调度方面，冷启动是各个厂商策略选择的首要因素。冷启动可以显着影响应用程序响应性，进而影响用户体验，此外实例生命周期和闲置实例回收的策略选择主要取决与冷启动，I/O吞吐量和网络吞吐量也可能会因为冷启动问题导致不必要的资源争用和延长执行时间。为了更好的说明冷启动的无服务平台中的巨大影响，在§3中，本文进一步描述冷启动问题。

# 3. 冷启动

本文已在前面展示了冷启动是无服务器平台中性能的一项关键瓶颈，这一节中，本文将继续深入冷启动，分析冷启动的成因（§3.1）以及描述针对冷启动更细致的实验结果（§3.2），最后本节给出了一些关于冷启动问题的思考和优化（§3.3）。

## 3.1 冷启动过程中发生了什么

Serverless平台自动配置和自动可扩展性是这些FaaS的杀手级功能。无需管理，云提供商将根据实际传入负载为用户提供基础架构。这种动态配置的一个缺点是称为“冷启动”的现象。 基本上，一段时间未使用的应用程序需要更长的时间来启动和处理第一个请求。 云提供商保留了一大堆通用的worker。 每当无服务器应用程序需要扩展时，无论是0到1个实例，还是从N到N 1，运行时都会选择一个备用worker并将其配置为服务于指定的应用程序。此过程需要时间，因此应用程序事件处理的延迟会增加。图1描述了“冷启动”的一系列过程：



![图1](https://msdnshared.blob.core.windows.net/media/2018/02/coldstart-1024x535.jpg)

**图1：空闲worker冷启动的整个流程**

## 3.2 冷启动测试

New Relic网站在这冷启动方面进行了一些简单的观察，Mikhail Shilkov在对于冷启动进行了一些测试并展示了他的实验结果。Liang Wang等人研究了实例放置的冷启动延迟。

观察冷启动时间相对简单——使用来自New Relic Infrastructure的AWS Lambda集成的数据，New Relic网站进行了一些测试，尽管冷启动时间大部分情况下，可以在 50ms 以内。而这是对于 Node.js 应用来说，对于拥有虚拟机的 Java 和 C# 可能就没有那么幸运了，差距可能达到十几倍。

Mikhail Shilkov 一开始使用了Node.js进行测试。Javascript可能是迄今为止无服务器应用程序最流行的语言。 因此，比较3个云提供商在Javascript中的表现方式是有意义的。 基础测试测量“Hello World”类型函数的冷启动。 函数没有依赖关系，因此部署包非常小。在测试中，AWS显然表现最好。 GCP位居第二，Azure是最慢的。Mikhail Shilkov 进一步对不同编程语言间进行了比较，Azure支持更多语言，包括Python和Java，但它们的冷启动问题十分严重。 

Liang Wang等人研究了实例放置的冷启动延迟。AWS中，检查了两种类型的冷启动事件：在（1）以前从未见过的新VM上启动，以及（2）在现有VM上启动函数实例。 直观地，情况（1）应该具有比（2）明显更长的冷启动延迟，因为情况（1）可能涉及启动新VM。 但是，发现案例（1）一般只略长于（2）。另外，发现的最小VM内核正常运行时间（来自`/proc/uptime`）为132秒，表明VM已在调用之前启动。因此，AWS拥有一个准备好的VM池。 情况（1）中的额外延迟更可能通过调度（例如，选择VM）而不是启动VM来引入。函数内存和语言影响冷启动延迟，比如Python 2.7实现了最低中位冷启动延迟（167-171 ms），而Java函数的延迟明显高于其他语言（ 824-974 ms）。 冷启动延迟通常随着函数内存的增加而降低。 一种可能的解释是AWS会根据内存大小按比例分配CPU功率; 随着CPU功率的增加，环境设置变得更快。由于AWS的实例放置策略，可以在同一VM上同时启动许多函数实例。 在这种情况下，随着更多实例同时启动，冷启动延迟会增加。 比如，在给定VM上启动具有128 MB内存的基于Python 2.7的函数的20个函数实例平均花费1,321 ms，这比在同一VM上启动1个函数实例（186 ms）慢约7倍。Azure和Google。Google也会按比例分配内存，但Google内存大小对冷启动延迟的影响要大于AWS。 在Azure中启动函数实例需要更长的时间，尽管它们的实例总是分配1.5 GB的内存。 Azure中的冷启动延迟中位数为3,640毫秒。 漫长的延迟是由Azure所知并正在努力改进的平台中的设计和工程问题引起的。

以上结果表明，当空闲Lambda收到请求时，必须加载代码，并且可以预期响应时间会增加。 在某些情况下，这种差异可能是极端的：如果一个简单的lambda在20ms以内响应，如果它闲置超过一个小时，则需要800ms才能响应。在Yan Cui的一次探索中，显示每次同时调用Lambda都有自己的冷启动开销。 这意味着，对于不经常使用的函数而言，冷启动或许不是一个问题，对于看到大量突然激增的函数，它可能会变得更糟。 使用无服务器的最常见原因是它可以更快地推出新函数。 如果在很少使用服务或看到使用突然激增的情况下冷启动速度减慢，那是不是意味着会对着性能造成无法预估的影响？

## 3.3 冷启动问题的优化

既然已经通过测试对serverless性能有了了解，那么就可以开始解决如何构建解决方案以避免它的问题。本节从多个角度探讨了冷启动问题的优化手段。

### 3.3.1 代码的优化

首先，尽量选择一些延迟较低的语言，比如通用的语言JavaScript。 §3.2中几种实验结果表明，JavaScript在主流serverless平台中都表现较好。尽管理想情况是对运行的任何语言都处于较好的优化状态。 希望这些语言在未来表现更好，但是现在，坚持使用上面更加通用的语言。

其次，尽量编写一些轻量级代码，部署代码时，依赖项将作为文件添加到应用程序中。应用程序所需的所有代码最终都会加载到内存中，这对于更大的应用程序来说需要更长的时间。因此，如果有大量的依赖关系，将获得更长的冷启动，因为文件的I / O操作时间增加，以及将更大的应用程序加载到内存所需的时间更长。一些JavaScript编写函数npm树往往很大。这不仅会增加应用程序的大小，还会增加Azure文件必须处理的文件数量，从而导致进一步减速。

编写一些高效代码。有时缩短冷启动答案只是编写更有效的代码。首先，尝试尽可能多地进行异步处理。如果有重量级同步调用阻止您的代码完成，函数将无法正常运行。在此过程中，尽量减少代码启动前必须完成的工作量，并避免使用占用大量CPU的代码。

### 3.3.2 保持热启动

Yan Cui的实验表明，AWS Lambda可以将容器保持大约45分钟。 既然冷启动十分耗时，那么是否可以尽量少的让容器陷入冷启动？

WarmUP的口号是“Keep your lambdas warm during Winter.”，它本质就是通过这样一个思路写得一个工具。

为了防止容器停机，以某种频率向函数发送虚拟请求，称为热身调用。 当然，需要对Lambda进行必要的更改，以区分热身调用和实际调用。由于热身调用，serverless平台将保持容器温暖，将永远不会遇到冷启动。 但事情并非如此直截了当。 

一个热身调用可以保持一个容器温暖，但如果有更多的容器，如何保持温暖？ 如果在生产中使用Lambda，则可能会有多个容器应该同时启动。 需要并行进行热身调用以保持所需的容器数量。 此时还有两个风险：1）保持所有容器忙于热身调用，并且真正的调用找不到运行的地方。 这再次导致真正的呼叫冷启动；2）一个容器中的Lambda函数可以一次捕获所有调用，这可能会在一段时间后使其他容器失效。

为了解决第一个问题，WarmUP中发明了一种方法。 如果想一直保持N个容器，WarmUP不会连续发送N个热身调用。 相反，更频繁地发送N / 2 个热身调用，并且在R小于N / 2的情况下发送N个热身调用。 例如; 如果想一次保留10个容器，可以每5分钟发送5到10个随机调用。 通过这种方式，可以确保每30分钟阻止所有容器，同时保持Lambdas的整个时间。为了解决第二个问题，应该稍微等待Lambda（比如100ms，它可以在WarmUP配置），同时调度热身调用。 这样，单个容器不会捕获所有请求，可以同时保持所需的容器数量。

一段时间后，应用程序上的负载会增加，这意味着需要保留更多容器以避免延迟。 在这种情况下，需要增加对Lambda容器的并行调用次数。 同样，如果流量遵循随时间减少的模式，则可能需要减少并行呼叫的数量。 在这种情况下，最好有一个比例因子来减少或增加容器的数量，比如加倍或削减一半。

### 3.3.3 SOCK

> todo



> 其他todo





# 参考

* [Serverless 应用开发指南](https://serverless.ink/)
* [Understanding Serverless Cold Start](https://blogs.msdn.microsoft.com/appserviceteam/2018/02/07/understanding-serverless-cold-start/)
* [Understanding AWS Lambda Performance](https://blog.newrelic.com/technology/aws-lambda-cold-start-optimization/)
* [AWS journey — API Gateway & Lambda & VPC performance](https://www.robertvojta.com/aws-journey-api-gateway-lambda-vpc-performance/)
* [Everything you need to know about cold starts in AWS Lambda](https://hackernoon.com/cold-starts-in-aws-lambda-f9e3432adbf0)
* [Keeping Functions Warm](https://serverless.com/blog/keep-your-lambdas-warm/)
* [Serverless: Cold Start War](https://mikhail.io/2018/08/serverless-cold-start-war/)

